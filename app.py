import io
import re
from typing import List, Optional
from urllib.parse import urljoin

import requests
from bs4 import BeautifulSoup
from readability import Document
from PIL import Image
from pptx import Presentation
from pptx.util import Pt
from pptx.dml.color import RGBColor
from pptx.enum.shapes import PP_PLACEHOLDER
import streamlit as st
from openai import OpenAI

APP_VERSION = "press2ppt v1.8 (image fix)"

# ========= è¨­å®š =========
TEMPLATE_PATH = "templates/cuprum_template.pptx"
DEFAULT_FONTS = ["Meiryo", "Yu Gothic UI", "MS UI Gothic", "Calibri"]

# ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
TITLE_COLOR = RGBColor(255, 255, 255)
TITLE_SIZE_PT = 28
TITLE_BOLD = True

BODY_COLOR = RGBColor(0, 153, 153)
BODY_SIZE_PT = 24
BODY_BOLD = True

# ãƒ­ã‚´ç­‰ã®é™¤å¤–è¨­å®š
IMG_EXCLUDE_RE = re.compile(
    r"(?:^|[-_/])(logo|favicon|sprite|badge|mark|header|footer|og_image|common/images/og_image\.png)\b",
    re.IGNORECASE,
)
EXACT_IMG_BLACKLIST = {
    "https://www.jx-nmm.com/common/images/og_image.png",
    "http://www.jx-nmm.com/common/images/og_image.png",
}

# ========= è¿½åŠ : HEIC/AVIFå¯¾å¿œ =========
HEIF_OK = False
AVIF_OK = False
try:
    import pillow_heif
    pillow_heif.register_heif_opener()
    HEIF_OK = True
except Exception:
    pass

try:
    import pillow_avif
    AVIF_OK = True
except Exception:
    pass


def _open_image_any(file_obj) -> Optional[Image.Image]:
    try:
        if hasattr(file_obj, "read"):
            data = file_obj.read()
            try:
                file_obj.seek(0)
            except Exception:
                pass
        elif isinstance(file_obj, (bytes, bytearray)):
            data = file_obj
        else:
            data = file_obj.getvalue()
        buf = io.BytesIO(data)
        img = Image.open(buf)
        if getattr(img, "is_animated", False):
            img.seek(0)
        return img.convert("RGB")
    except Exception:
        return None


# ========= OpenAI =========
def get_client(api_key: Optional[str]):
    try:
        return OpenAI(api_key=api_key) if api_key else OpenAI()
    except Exception:
        return None


# ========= HTMLå–å¾— =========
def fetch_html_public(url: str) -> str:
    r = requests.get(url, timeout=20, headers={"User-Agent": "Mozilla/5.0"})
    r.raise_for_status()
    return r.text


def _best_from_srcset(srcset: str) -> Optional[str]:
    try:
        parts = [p.strip() for p in srcset.split(",") if p.strip()]
        pairs = []
        for p in parts:
            s = p.split()
            if len(s) == 1:
                pairs.append((s[0], 0))
            else:
                w = 0
                try:
                    if s[1].endswith("w"):
                        w = int(s[1][:-1])
                except Exception:
                    pass
                pairs.append((s[0], w))
        pairs.sort(key=lambda x: x[1], reverse=True)
        return pairs[0][0] if pairs else None
    except Exception:
        return None


def parse_page(url: str) -> dict:
    html = fetch_html_public(url)
    return _parse_common(html, base_url=url)


def _parse_common(html: str, base_url: str = "") -> dict:
    doc = Document(html)
    title = (doc.short_title() or "").strip()
    if not title:
        try:
            head = BeautifulSoup(html, "lxml").find("head")
            if head:
                t = head.find("title")
                if t and t.get_text(strip=True):
                    title = t.get_text(strip=True)
        except Exception:
            pass

    main_html = doc.summary(html_partial=True)
    soup = BeautifulSoup(main_html, "lxml")

    ps = [p.get_text(" ", strip=True) for p in soup.find_all("p")]
    text = " ".join(ps)

    def abs_url(u: str) -> str:
        if not base_url:
            return u
        if u and u.startswith("/"):
            return urljoin(base_url, u)
        return u

    urls: List[str] = []
    for img in soup.find_all("img"):
        cand = img.get("src") or img.get("data-src") or img.get("data-original")
        if not cand and img.get("srcset"):
            cand = _best_from_srcset(img.get("srcset"))
        if cand:
            urls.append(abs_url(cand))

    for pic in soup.find_all("picture"):
        for src in pic.find_all("source"):
            srcset = src.get("srcset")
            if srcset:
                cand = _best_from_srcset(srcset)
                if cand:
                    urls.append(abs_url(cand))

    try:
        head = BeautifulSoup(html, "lxml").find("head")
        if head:
            for prop in ["og:image", "twitter:image"]:
                tag = head.find("meta", property=prop) or head.find("meta", attrs={"name": prop})
                if tag and tag.get("content"):
                    urls.append(abs_url(tag["content"]))
    except Exception:
        pass

    cleaned = []
    for u in urls:
        if not u or u.startswith("data:"):
            continue
        low = u.lower()
        u_noquery = re.sub(r"[?#].*$", "", u)
        if u_noquery in EXACT_IMG_BLACKLIST:
            continue
        if IMG_EXCLUDE_RE.search(low):
            continue
        cleaned.append(u)

    uniq, seen = [], set()
    for u in cleaned:
        base = re.sub(r"[?#].*$", "", u)
        if base not in seen:
            uniq.append(u)
            seen.add(base)

    return {"title": title, "text": text, "images": uniq}


# ========= è¦ç´„å‡¦ç† =========
SYS_TITLER = (
    "ã‚ãªãŸã¯æ—¥æœ¬èªã®PRã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚25æ–‡å­—ã‚’è¶…ãˆã‚‹å ´åˆã®ã¿è‡ªç„¶ãªè¦‹å‡ºã—ã«çŸ­ç¸®ã€‚"
    "å¥èª­ç‚¹å«ã‚25æ–‡å­—ä»¥å†…ã€å›ºæœ‰åè©ã¯å„ªå…ˆã—ã¦ä¿æŒã€‚"
)
SYS_SUMMARY = (
    "ã‚ãªãŸã¯æ—¥æœ¬èªã®PRã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä¼æ¥­ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ã®è¦æ—¨ã‚’ã€"
    "æŒ‡å®šã®ä¸Šé™æ–‡å­—æ•°ä»¥å†…ã§ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚"
    "ä¸Šé™æ–‡å­—æ•°ã®90%~95%ã®æ–‡å­—æ•°ã«å¿…ãšã—ã¦"
    "æ–‡ã‚’é€”ä¸­ã§åˆ‡ã‚‰ãšã€å¥ç‚¹ã€Œã€‚ã€ã§å®Œçµã•ã›ã‚‹ã“ã¨ã€‚"
    "å¿…è¦ã«å¿œã˜ã¦çŸ­æ–‡ã«åˆ†ã‘ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚"
    "ä½“è¨€æ­¢ã‚ã‚„é‡è¨€ã¯é¿ã‘ã€å›ºæœ‰åè©ã¯ä¿æŒã€‚ã§ã™ã¾ã™èª¿ã€‚"
    "JXé‡‘å±æ ªå¼ä¼šç¤¾ã‚„JXé‡‘å±ã€JXç­‰ã®ä¸»èªã¯å¿…ãšçœç•¥ã—ã€ãã‚Œã§ã‚‚æ„å‘³ãŒé€šã‚‹ã‚ˆã†ã«ã€‚"
    "å†—é•·è¡¨ç¾ã‚„é‡è¤‡ã‚’å‰Šã‚Šã€æ„å‘³ã‚’ä¿ã£ãŸã¾ã¾ä¸Šé™ä»¥å†…ã«åã‚ã¦ãã ã•ã„ã€‚"
)


def gpt_shorten_title(client: Optional[OpenAI], title: str) -> str:
    if len(title) <= 25 or not client:
        return title[:25]
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": SYS_TITLER},
                {"role": "user", "content": f"å…ƒã‚¿ã‚¤ãƒˆãƒ«ï¼š{title}\n25æ–‡å­—ä»¥å†…ã«çŸ­ã"},
            ],
            temperature=0.2,
        )
        return (resp.choices[0].message.content or "").strip()[:25]
    except Exception:
        return title[:25]


def offline_summary(text: str) -> str:
    if not text:
        return ""
    sentences = re.split(r"(?<=[ã€‚ï¼ï¼Ÿ!?])", text)
    chunk = "".join(sentences[:3])
    chunk = re.sub(r"\s+", " ", chunk)
    return chunk


def _tidy_clamp_to_limit(s: str, limit: int) -> str:
    s = s.strip()
    if len(s) <= limit:
        return s
    candidates = ["ã€‚", "ï¼", "ï¼Ÿ", "!", "?", "â€¦"]
    cut_pos = -1
    for ch in candidates:
        p = s.rfind(ch, 0, limit)
        if p > cut_pos:
            cut_pos = p
    if cut_pos >= 0 and cut_pos >= int(limit * 0.5):
        return s[:cut_pos + 1].strip()
    return s[:limit].rstrip("ãƒ»ã€ï¼Œ,ï¼ˆ(").rstrip()


def gpt_summarize_body(client: Optional[OpenAI], text: str, max_len: int = 120) -> str:
    head = (text or "")[:4000]
    base = offline_summary(head)
    if not client:
        return _tidy_clamp_to_limit(base, max_len)
    try:
        prompt_user = (
            f"{head}\n\n"
            f"ä¸Šé™{max_len}æ–‡å­—ã§ã€é‡è¦ç‚¹ã‚’è½ã¨ã•ãšç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚"
            f"æ–‡ã¯é€”ä¸­ã§åˆ‡ã‚‰ãšã€å¥ç‚¹ã§å®Œçµã•ã›ã¦ãã ã•ã„ã€‚"
        )
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": SYS_SUMMARY},
                {"role": "user", "content": prompt_user},
            ],
            temperature=0.2,
        )
        s = (resp.choices[0].message.content or "").strip()
        return _tidy_clamp_to_limit(s, max_len)
    except Exception:
        return _tidy_clamp_to_limit(base, max_len)


def do_summary(text: str, max_len: int, api_key: Optional[str]) -> tuple[str, str]:
    client = get_client(api_key or None)
    if client:
        try:
            s = gpt_summarize_body(client, text, max_len)
            return s, "GPT"
        except Exception:
            pass
    s = gpt_summarize_body(None, text, max_len)
    return s, "OFFLINE"


# ========= ç”»åƒDL =========
def download_images(urls: List[str], limit: int = 4) -> List[Image.Image]:
    imgs: List[Image.Image] = []
    for u in urls[:limit]:
        try:
            r = requests.get(u, timeout=30, headers={"User-Agent": "Mozilla/5.0"})
            r.raise_for_status()
            img = Image.open(io.BytesIO(r.content)).convert("RGB")
            if img.width < 300 or img.height < 180:
                continue
            imgs.append(img)
        except Exception:
            continue
    return imgs


# ========= PowerPointç”Ÿæˆ =========
def _first_placeholder(slide, types: tuple[int, ...]) -> Optional[object]:
    for ph in slide.placeholders:
        try:
            if ph.placeholder_format.type in types:
                return ph
        except Exception:
            continue
    return None


def _set_text(shape, text: str, size_pt: int, color: RGBColor, bold: bool):
    try:
        if not getattr(shape, "has_text_frame", False):
            return
        tf = shape.text_frame
        tf.clear()
        p = tf.paragraphs[0]
        run = p.add_run()
        run.text = text
        for fn in DEFAULT_FONTS:
            try:
                run.font.name = fn
                break
            except Exception:
                continue
        run.font.size = Pt(size_pt)
        run.font.color.rgb = color
        run.font.bold = bold
    except Exception:
        pass


def get_layout_by_name(prs, name: str):
    for layout in prs.slide_layouts:
        if layout.name == name:
            return layout
    return None


def _place_image_contain(slide, ph, img: Image.Image):
    buf = io.BytesIO()
    img.convert("RGB").save(buf, format="JPEG", quality=92)
    buf.seek(0)

    frame_w = ph.width
    frame_h = ph.height
    frame_left = ph.left
    frame_top = ph.top

    iw, ih = img.size
    a_img = iw / ih
    a_frame = frame_w / frame_h

    if a_img >= a_frame:
        w = frame_w
        h = int(frame_w / a_img)
    else:
        h = frame_h
        w = int(frame_h * a_img)

    left = frame_left + int((frame_w - w) / 2)
    top = frame_top + int((frame_h - h) / 2)

    pic = slide.shapes.add_picture(buf, left, top, width=w, height=h)
    try:
        ph.element.getparent().remove(ph.element)
    except Exception:
        pass
    return pic


def build_pptx(template_path: str, title: str, summary: str, images: List[Image.Image], fit_mode: str) -> bytes:
    prs = Presentation(template_path)

    n = min(len(images), 3)
    layout_name = {
        0: "Cuprum Title+Body",
        1: "Cuprum Title+Body+1Pic",
        2: "Cuprum Title+Body+2Pic",
        3: "Cuprum Title+Body+3Pic",
    }[n]
    layout = get_layout_by_name(prs, layout_name) or prs.slide_layouts[0]
    slide = prs.slides.add_slide(layout)

    title_ph = _first_placeholder(slide, (PP_PLACEHOLDER.TITLE, PP_PLACEHOLDER.CENTER_TITLE))
    if title_ph is None:
        for ph in slide.placeholders:
            if "ã‚¿ã‚¤ãƒˆãƒ«" in getattr(ph, "name", ""):
                title_ph = ph
                break
    if title_ph is not None:
        _set_text(title_ph, title, TITLE_SIZE_PT, TITLE_COLOR, TITLE_BOLD)

    body_ph = _first_placeholder(slide, (PP_PLACEHOLDER.BODY,))
    if body_ph is None:
        body_ph = _first_placeholder(slide, (PP_PLACEHOLDER.CONTENT,))
    if body_ph is None:
        for ph in slide.placeholders:
            if "ãƒ†ã‚­ã‚¹ãƒˆ" in getattr(ph, "name", ""):
                body_ph = ph
                break
    if body_ph is not None:
        _set_text(body_ph, summary, BODY_SIZE_PT, BODY_COLOR, BODY_BOLD)

    pic_placeholders = []
    for ph in slide.placeholders:
        try:
            if ph.placeholder_format.type == PP_PLACEHOLDER.PICTURE:
                pic_placeholders.append(ph)
        except Exception:
            continue
    pic_placeholders.sort(key=lambda sh: (sh.left, sh.top))

    use_n = min(len(images), len(pic_placeholders))
    for i in range(use_n):
        ph = pic_placeholders[i]
        img = images[i]
        if fit_mode.startswith("åã‚ã‚‹"):
            _place_image_contain(slide, ph, img)
        else:
            buf = io.BytesIO()
            img.convert("RGB").save(buf, format="JPEG")
            buf.seek(0)
            try:
                ph.insert_picture(buf)
            except Exception:
                slide.shapes.add_picture(buf, ph.left, ph.top, width=ph.width)

    out = io.BytesIO()
    prs.save(out)
    out.seek(0)
    return out.read()


# ========= UI =========
st.set_page_config(page_title="ãƒ—ãƒ¬ã‚¹URL / ã‚³ãƒ”ãƒš â†’ Cuprum PPT", page_icon="ğŸ§©", layout="wide")
st.title(f"ãƒ—ãƒ¬ã‚¹URL or ã‚³ãƒ”ãƒšï¼‹ç”»åƒ â†’ Cuprumãƒ†ãƒ³ãƒ—ãƒ¬è‡ªå‹•ä½œæˆï½œ{APP_VERSION}")

with st.sidebar:
    st.header("è¨­å®š")
    template_file = st.file_uploader("ãƒ†ãƒ³ãƒ—ãƒ¬ï¼ˆ.pptxï¼‰ã‚’å·®ã—æ›¿ãˆå¯", type=["pptx"])
    api_key = st.text_input("OpenAI API Keyï¼ˆæœªå…¥åŠ›/å¤±æ•—æ™‚ã¯ã‚ªãƒ•ãƒ©ã‚¤ãƒ³è¦ç´„ï¼‰", type="password")
    max_images = st.slider("æœ€å¤§ç”»åƒæ•°ï¼ˆå…ˆé ­ã‹ã‚‰ä½¿ç”¨ã€ä¸Šé™3æšï¼‰", 0, 6, 3)
    summary_length = st.slider("è¦ç´„æ–‡å­—æ•°ä¸Šé™ï¼ˆç›®å®‰ï¼‰", 120, 400, 160, 20)
    fit_mode = st.selectbox("ç”»åƒã®ã¯ã‚è¾¼ã¿æ–¹æ³•", ["åã‚ã‚‹ï¼ˆä½™ç™½ã‚ã‚Šãƒ»å…¨ä½“è¡¨ç¤ºï¼‰", "åŸ‹ã‚ã‚‹ï¼ˆãƒˆãƒªãƒŸãƒ³ã‚°ã‚ã‚Šï¼‰"], index=0)
    show_debug = st.checkbox("ğŸ§© ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã‚’è¡¨ç¤º", value=True)
    st.caption("ã‚¿ã‚¤ãƒˆãƒ«>25æ–‡å­—ã¯çŸ­ç¸®ã€‚æœ¬æ–‡ã¯ä¸Šé™æ–‡å­—æ•°ã§è¦ç´„ï¼ˆã‚³ãƒ”ãƒšç‰ˆã¯è¦ç´„ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã€‚")

mode = st.radio("å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰", ["ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ãƒ¢ãƒ¼ãƒ‰", "Sharepointã‚³ãƒ”ãƒšãƒ¢ãƒ¼ãƒ‰"], horizontal=True)

# å…±æœ‰ã®ä½œæ¥­ç”¨å¤‰æ•°
title_final = ""
summary_final = ""
engine_used = "NO_SUMMARY"
images: List[Image.Image] = []
parsed_preview = None

# ============== ãƒ¢ãƒ¼ãƒ‰1ï¼šURLãƒ¢ãƒ¼ãƒ‰ ==============
if mode == "ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ãƒ¢ãƒ¼ãƒ‰":
    url = st.text_input("ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ã®URLï¼ˆç¤¾å¤–ã‚µã‚¤ãƒˆæ¨å¥¨ï¼‰")
    if st.button("â‘  å†…å®¹ã‚’æŠ½å‡ºï¼ˆURLã‹ã‚‰ï¼‰"):
        try:
            parsed = parse_page(url)
            st.session_state["parsed_url"] = parsed
            st.success("æŠ½å‡ºã—ã¾ã—ãŸã€‚ä¸‹ã§è¦ç´„ãƒ»ç”»åƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        except Exception as e:
            st.error(f"æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {type(e).__name__}: {e}")

    parsed = st.session_state.get("parsed_url")
    if parsed:
        st.subheader("æŠ½å‡ºçµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆURLãƒ¢ãƒ¼ãƒ‰ï¼‰")
        left, right = st.columns([2, 1])
        with left:
            st.write("æŠ½å‡ºã‚¿ã‚¤ãƒˆãƒ«:", parsed.get("title") or "(ãªã—)")
            raw_text = parsed.get("text") or ""
            st.write("æœ¬æ–‡ï¼ˆå…ˆé ­ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰:", raw_text[:300] + ("â€¦" if len(raw_text) > 300 else ""))
        with right:
            st.write("å€™è£œç”»åƒURLï¼ˆå…ˆé ­ã‹ã‚‰ä½¿ç”¨ï¼‰")
            candidates = parsed.get("images", [])
            if candidates:
                for i, u in enumerate(candidates[:max_images]):
                    st.write(f"{i+1}. {u}")
            else:
                st.write("ï¼ˆç”»åƒå€™è£œãªã—ï¼‰")

        client = get_client(api_key or None)
        title_final = gpt_shorten_title(client, parsed.get("title") or "ï¼ˆç„¡é¡Œï¼‰")

        summary_final, engine_used = do_summary(parsed.get("text") or "", summary_length, api_key)
        st.info(f"è¦ç´„ã‚¨ãƒ³ã‚¸ãƒ³: {engine_used} / åŸæ–‡: {len(parsed.get('text') or '')}æ–‡å­— â†’ å‡ºåŠ›: {len(summary_final)}æ–‡å­—")

        sel_urls = parsed.get("images", [])[:max_images]
        images = download_images(sel_urls, limit=max_images)
        if images:
            cols = st.columns(min(len(images), 3))
            for i, img in enumerate(images):
                with cols[i % len(cols)]:
                    st.image(img, caption=f"Image {i+1}", use_container_width=True)
        else:
            st.info("è¡¨ç¤ºå¯èƒ½ãªç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        parsed_preview = {"title": title_final, "summary": summary_final}

# ============== ãƒ¢ãƒ¼ãƒ‰2ï¼šã‚³ãƒ”ãƒšï¼‹ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ==============
else:
    manual_title = st.text_input("è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆã‚³ãƒ”ãƒšï¼‰")
    manual_body = st.text_area("è¨˜äº‹æœ¬æ–‡ï¼ˆã‚³ãƒ”ãƒšï¼‰", height=220)
    colA, colB = st.columns(2)
    with colA:
        do_summarize = st.checkbox("æœ¬æ–‡ã‚’è¦ç´„ã™ã‚‹ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä¸Šé™æ–‡å­—æ•°ã‚’ä½¿ç”¨ï¼‰", value=True)
    with colB:
        do_shorten_title = st.checkbox("ã‚¿ã‚¤ãƒˆãƒ«ãŒ25æ–‡å­—è¶…ãªã‚‰çŸ­ç¸®ã™ã‚‹", value=True)

    uploaded_files = st.file_uploader(
        "ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆæœ€å¤§3æšã¾ã§ï¼‰",
        type=[
            "jpg", "jpeg", "png", "webp", "bmp", "tiff", "tif", "gif",
            "heic", "heif",
            "avif"
        ],
        accept_multiple_files=True
    )

    with st.expander("å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæƒ…å ±", expanded=False):
        st.write(f"HEIC/HEIFå¯¾å¿œ: {'âœ…' if HEIF_OK else 'âš ï¸ pillow-heifæœªå°å…¥'}")
        st.write(f"AVIFå¯¾å¿œ: {'âœ…' if AVIF_OK else 'âš ï¸ pillow-avif-pluginæœªå°å…¥'}")

    if st.button("â‘  ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆï¼ˆã‚³ãƒ”ãƒšç‰ˆï¼‰"):
        if not manual_title and not manual_body:
            st.warning("ã‚¿ã‚¤ãƒˆãƒ«ã¾ãŸã¯æœ¬æ–‡ã®ã©ã¡ã‚‰ã‹ã¯å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            client = get_client(api_key or None)
            if do_shorten_title:
                title_final = gpt_shorten_title(client, manual_title or "ï¼ˆç„¡é¡Œï¼‰")
            else:
                title_final = (manual_title or "ï¼ˆç„¡é¡Œï¼‰")[:100]

            if do_summarize:
                summary_final, engine_used = do_summary(manual_body or "", summary_length, api_key)
            else:
                summary_final = (manual_body or "")[:summary_length]
                engine_used = "NO_SUMMARY"

            images = []
            if uploaded_files:
                for f in uploaded_files[:3]:
                    img = _open_image_any(f)
                    if img is None:
                        continue
                    if img.width < 300 or img.height < 180:
                        continue
                    images.append(img)

            st.session_state["manual_preview"] = {
                "title": title_final,
                "summary": summary_final,
                "images_len": len(images),
                "engine": engine_used,
                "raw_len": len(manual_body or ""),
                "out_len": len(summary_final or ""),
            }
            st.session_state["manual_images"] = images
            st.success("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä½œæˆã—ã¾ã—ãŸã€‚ä¸‹ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    manual_prev = st.session_state.get("manual_preview")
    images = st.session_state.get("manual_images", [])
    if manual_prev:
        st.subheader("æŠ½å‡ºçµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆã‚³ãƒ”ãƒšç‰ˆï¼‰")
        st.write("**ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæœ€çµ‚ï¼‰**:", manual_prev["title"])
        st.write(f"**æœ¬æ–‡ï¼ˆ{manual_prev['out_len']}æ–‡å­— / ã‚¨ãƒ³ã‚¸ãƒ³: {manual_prev['engine']} / åŸæ–‡{manual_prev['raw_len']}æ–‡å­—ï¼‰**:")
        st.write(manual_prev["summary"])
        if images:
            cols = st.columns(min(len(images), 3))
            for i, img in enumerate(images):
                with cols[i % len(cols)]:
                    st.image(img, caption=f"Uploaded {i+1}", use_container_width=True)
        else:
            st.info("ç”»åƒã¯æœªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ã™ã€‚")

        title_final = manual_prev["title"]
        summary_final = manual_prev["summary"]
        engine_used = manual_prev["engine"]
        parsed_preview = manual_prev

# ============== å…±é€šï¼šPPTç”Ÿæˆï¼ˆãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã‚ã‚Šï¼‰ ==============
st.markdown("---")
if st.button("â‘¡ PPTã‚’ä½œæˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
    try:
        tpl_path = TEMPLATE_PATH
        if template_file is not None:
            tpl_path = "uploaded_template.pptx"
            with open(tpl_path, "wb") as f:
                f.write(template_file.read())

        import os
        if not os.path.exists(tpl_path):
            st.error(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {tpl_path}")
        elif not parsed_preview:
            st.error("å…ˆã«â‘ ã§ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        else:
            if show_debug:
                # slide ã¯ build å†…ãªã®ã§ã“ã“ã§ã¯æ¦‚æ³ã ã‘
                st.write({
                    "layout_candidates": [
                        "Cuprum Title+Body",
                        "Cuprum Title+Body+1Pic",
                        "Cuprum Title+Body+2Pic",
                        "Cuprum Title+Body+3Pic",
                    ],
                    "images_count": len(images or []),
                    "fit_mode": fit_mode,
                    "title_preview": (title_final[:40] + ("â€¦" if len(title_final) > 40 else "")),
                    "summary_preview": (summary_final[:60] + ("â€¦" if len(summary_final) > 60 else "")),
                    "engine_used": engine_used,
                })

            ppt_bytes = build_pptx(
                tpl_path,
                title_final or "ï¼ˆç„¡é¡Œï¼‰",
                summary_final or "",
                images or [],
                fit_mode=fit_mode
            )
            if not isinstance(ppt_bytes, (bytes, bytearray)) or len(ppt_bytes) == 0:
                st.error("PPTç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆãƒ‡ãƒ¼ã‚¿ä¸æ­£ã¾ãŸã¯ç©ºãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã€‚")
            else:
                st.success("PPTã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
                st.download_button(
                    "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=ppt_bytes,
                    file_name="press_auto.pptx",
                    mime="application/vnd.openxmlformats-officedocument.presentationml.presentation",
                )
    except Exception as e:
        import traceback
        st.error(f"PPTç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {type(e).__name__}: {e}")
        st.code("".join(traceback.format_exc()))
else:
    st.caption("â‘  æŠ½å‡º/ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ â†’ â‘¡ PPTä½œæˆ ã®é †ã§æ“ä½œã—ã¦ãã ã•ã„ã€‚")
